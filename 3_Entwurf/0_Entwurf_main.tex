\chapter{Entwurf}
Einleitung zum Entwurf

\section{Anforderungen}
In diesem Abschnitt sollen zunächst die Anforderungen genannt werden, anhand derer sich die Arbeitspakete identifizieren lassen. Das Ziel ist: Der \dscubesat soll in der Lage sein seine eigene Position mittels GPS zu bestimmen. Einige Anforderungen ergeben sich außerdem aus der Konfiguration des Frontends, weshalb auch diese hier besprochen wird.

\subsection{Anzahl der Kanäle} Wie in Abschnitt \ref{positionsbestimmung} erläutert werden zur Positionsbestimmung die Daten von mindesten 4 GPS Satelliten benötigt. Daraus ergibt sich die Anforderung, dass der Empfänger mindestens 4 Kanäle zum Tracking der Signale haben muss. Weiterhin soll bei einem Verbindungsabbruch zu einem der Satelliten die Positionsbestimmung nicht abbrechen, weshalb $>4$ Kanäle erforderlich sind. Außerdem steigt die Genauigkeit der Positionsbestimmung mit mehr Satelliten. Deshalb soll der hier entwickelte GPS Empfänger mindestens 6 Kanäle umfassen.

\subsection{Rohdatenpuffer}
Voraussetzung für das Tracking ist die erfolgreiche Acquisition, wofür eine gewisse Menge Rohdaten benötigt werden. Aufgrund der Bitwechsel Problemetik (\ref{DatenmengeAcq}) beträgt die maximal sinnvolle Pufferlänge $2\times\SI{10}{\ms}$. Für den Entwurf wurde sich an der Implementierung in der Simulation in \cite{borre2007software} orientiert, wo ein \SI{10}{\ms} Segment in der zweiten Phase der Acquisition verwendet wird.

\subsection{Komponenten und Schnittstellen des GPS Empfängers}
In \FR{GPS_UML_component1.pdf} ist ein Entwurf der Komponenten des GPS Empfängers dargestellt, und die von ihnen bereitgestellten bzw. benötigten Daten. Das Diagramm macht noch keine Aussage darüber wo (ob auf DSP oder FPGA) oder wie (Hardware oder Software) die Komponenten realisiert werden.

Die \emph{Frontend} Komponente ist hier nicht als direktes Abbild des MAX2769 ICs zu verstehen, sondern kann noch durch Code im FPGA abstrahiert werden. Bei der \emph{Rohdaten} Schnittstelle wird zudem erst einmal nicht unterschieden ob diese Segmentweise (wie von \emph{Acquisition} benötigt) oder als kontinuierlicher Datenstrom (wie von \emph{Trackingloop} benötigt) bereitgestellt werden. 

Die \emph{Acquisition} Komponente errechnet aus den Rohdaten die Loop Parameter (Dopplerverschiebung etc). Außerdem gelten die Rohdaten immer nur individuell für ein Segment Rohdaten und damit für einen bestimmten Zeitpunkt. Für die Acquisition selbst ist der Zeitpunkt nicht wichtig, aber beim Initialisieren der Trackingloops wird die Information benötigt, und muss daher irgendwo festgehalten werden. Dies ist durch die Schnittstelle \emph{Zeitstempel} symbolisiert.

Die Trackingloops erhalten von dem Frontend Rohdaten und demodulieren das Signal. Aus dem demodulierten Signal extrahiert die Komponente \emph{NAV Daten Extraktion} die NAV Daten. Wie in Abschnitt \ref{positionsbestimmung} erklärt, reichen die NAV Daten alleine zu Positionsbestimmung nicht aus. Deshalb benötigt die Komponente \emph{Positionsbestimmung} zusätzlich Informationen über die Codephase von den Trackingloops.


\FGimg[Komponentendiagramm GPS Empfänger]{GPS_UML_component1.pdf}{Die abstrahierten Komponenten des GPS Empfängers und die von ihnen benötigten bzw. bereitgestellten Daten.}{0.7\textwidth}


\subsection{Echtzeitanforderungen} \label{echtzeitanforderungen}
Die beiden Phasen Acquistion und Tracking haben unterschiedliche Echtzeitanforderungen: Das Tracking hat harte Echtzeitanforderungen: Erstens müssen laufend Träger- und Codekopie erzeugt und mit dem Eingangssignal multipliziert werden. Dies sind die höchsten Echtzeitanforderungen im \si{\nano\second} Bereich, da dies je Sample, also alle $1/f_S$ geschehen muss. Die Neuberechnung der Loop Parameter hat harte Echtzeitanforderungen im \si{\milli\second}, da dies lediglich nach jeder Integrationsdauer ($\gpsTcode=\SI{1}{\ms}$) passieren muss. Die Blöcke die lediglich Echtzeitanforderungen im \si{\milli\second} Bereich haben sind in \FR{Trackingloop.png} grün markiert.

Die Acquisition hat lediglich weiche Echtzeitanforderung im Sekundenbereich, da sich die Dopplerverschiebung nur relativ langsam verändert (schlimmstenfalls \SI{61}{\Hz/\second}, siehe \ref{maxdopplershift}). Falls die Acquisition länger als geplant dauert, kann der Trackingloop trotzdem noch einrasten wenn sich die Dopplerverschiebung nicht zu stark geändert hat.

\subsection{Arbeitsteilung FPGA/DSP}
% Acquisition im DSP
% Erfordert große Mengen Speicher und hoher Rechenaufwand. Floating Point
% Idee Vorberechnung im FPGA verworfen, Implementierungsaufwand Protokoll etc
% Tracking im FPGA. Tracking erfordert hohe Parallelität bei moderatem Rechenaufwand und hat harte Echtzeitanforderungen.
% Softcore Prozessor. Auswahl. Aufgabe
Das \comboard bietet mit dem DSP und dem FPGA zwei Rechenknoten an, die in verschiedenen Bereichen Vorteile und Nachteile haben: FPGAs eignen sich vor allem für gut parallelisierbare Aufgaben. Für sequentielle Aufgaben ist dagegen der Implementierungsaufwand hoch, da dies immer einen Zustandsautomaten erfordert. Im Falle des \comboard hat außerdem der DSP deutlich mehr Speicher zur Verfügung. Wie früher im Text schon besprochen haben die Acquisition und Tracking sehr unterschiedliche Anforderungen: Die Acquisition benötigt vor allem Speicher und der Ablauf (FFT, Maximumsuche, etc) ist vergleichsweise komplex. Die Echtzeitanforderungen sind bei der Acquisition nicht sehr hoch. Das Tracking dagegen hat harte Echtzeitanforderungen, aber der Rechenaufwand ist moderat, und der Ablauf ist recht einfach. Daher ist es sinnvoll die Aufgaben auf die beiden Komponenten aufzuteilen.

Der DSP kann seine Vorzüge bei der Acquisition ausspielen: Er hat einen großen Arbeitsspeicher, ist auf Signalverarbeitung ausgelegt und Programme können in einer Hochsprache wie C geschrieben werden, was nebenbei das Debugging vereinfacht.

Für das Tracking ist der FPGA ideal geeignet, da die $\geq 6$ Trackingkanäle in programmierbarer Hardware implementiert werden können und damit vollständig parallel ablaufen. Auch das Tracking erfordert allerdings einige Berechnungen, die sich einfacher in C als in VHDL beschreiben lassen. Um die Echtzeitanforderung einzuhalten werden diese Berechnungen aber nicht an den DSP übergeben. Stattdessen soll dies von einem Softcore Prozessor innerhalb FPGA der dort in programmierbarer Logik implement wird.

In \FR{GPS_UML_deployment1.png} ist die Verteilung der Komponenten auf die verschiedenen Rechenknoten dargestellt. Die Komponente \emph{Tracking} aus \FR{GPS_UML_component1.pdf} ist hier auf die zwei Knoten \emph{Softcore CPU} und \emph{Tracking} aufgeteilt worden: Für jeden Kanal existiert ein \emph{TrackingHW} Knoten, der die in \FR{Trackingloop.png} weiß eingefärbten Blöcke implementiert. Für alle Kanäle gemeinsam implementiert das auf dem Softcore Prozessor laufende Programm \emph{TrackingSW} die in \FR{Trackingloop.png} grün eingefärbten Blöcke. Zur Erinnerung: Die grün eingefärbten Blöcke waren zwar algorithmisch aufwändiger, mussten dafür aber mit einer geringeren Frequenz ausgeführt werden. Durch diese Arbeitsteilung werden die Ressourcen optimal ausgenutzt.

Im DSP soll die GPS Empfänger Anwendung laufen, die zum einen die Acquisition und zum anderen die weitere Signalverarbeitung zur NAV Daten Extraktion und Positionsbestimmung übernimmt. Auf der Hardware Ebene kommuniziert der DSP mit dem FPGA über die \gls{EBIU} Schnittstelle \cite{BlackfinHWReference}, die ein Interface für externen Speicher implementiert. 

\FGimg[Verteilungsdiagramm Dragsail GPS Empfänger]{GPS_UML_deployment1.png}{Verteilung der Komponenten auf die Rechenknoten des COM Boards}{0.9\textwidth}

\subsection{Auswahl des Softcore Prozessors}
Im vorherigen Abschnitt wurde bereits die Verwendung einer Softcore CPU für einige Berechnungen im FPGA erwähnt. In einem FPGA lassen sich (in gewissen Grenzen) beliebige digitale Schaltungen synthetisieren. Funktionsblöcke, werden dabei als IP-Cores oder Softcores bezeichnet, und werden zum Beispiel als VHDL Quellcode oder als Netzlisten angeboten. Eine Softcore CPU ist also ein Prozessorkern, der über den Quellcode beschrieben wird und damit in das restliche System eingebunden werden kann. Es gibt zahlreiche kostenlose und freie Softcore CPUs auf dem Markt\footnote{Ein Überblick gibt \cite{SoftcoreOverview}}. In diesem Abschnitt soll kurz die Auswahl der Softcore CPU für den GPS Empfänger erklärt und begründet werden. 

Üblicherweise bieten FPGA Hersteller bereits eigene Softcore CPUs an und als Teil der Entwicklungsumgebung Werkzeuge an um diese zu instantiieren. Für Xilinx ist dies z.B. der MicroBlaze Prozessor. Aus eigener Erfahrung verstecken jedoch die Entwurfswerkzeuge viel von der darunterliegenden Technik, wodurch das Design komplexer und weniger durchschaubar wird. Für den hier vorliegenden Fall sind die durch die CPU zu erledigenden Aufgaben relativ einfach, deshalb wurde nach einem Prozessor gesucht, der wenig Ressourcen verbraucht. Weiterhin sollte die für die Entwicklung verwendete Toolchain auf \emph{gcc} basieren, aus dem einfachen Grund, dass \emph{gcc} eine der bekanntesten Compiler Toolchains ist, in der Praxis bewährt ist und somit Einarbeitungszeit spart.

Die Wahl viel zunächst auf den Zylin ZPU Softcore, laut eigener Aussage die kleinste 32-bit CPU mit gcc Toolchain \cite{ZPUgithub}. Die ZPU ist ein Stack Prozessor, arbeitet also ohne Register. Das Prinzip ist ähnlich zu Taschenrechnern die mit Umgekehrt Polnischer Notation arbeiten. Zylin legt mit der ZPU Spezifikation zunächst einmal nur den Befehlscode fest. Es gibt zahlreiche Implementierungen mit verschiedenen Schwerpunkten. Leider ist durch diese Fragmentierung die Dokumentation sehr lückenhaft, und die Codequalität ist teilweise sehr schlecht. Nach mehreren Versuchen den ZPU Kern, in Form der ZPUFlex Implementierung, in das System zu integrieren wurde das Vorhaben aufgegeben.

Stattdessen wurde als Softcore der MBlite Core von Tamar Kranenburg ausgewählt. Der Entwickler hat den Prozessor in seiner Masterarbeit \cite{MBliteThesis} sehr gut dokumentiert und die Codequalität ist gut. Der MBlite Core ist eine Variante des Xilinx Microblaze und vollständig kompatibel dazu, womit die gcc Toolchain des Microblaze verwendet werden kann. Als Microblaze Variante ist er auch ein 32-bit Prozessor in Harvard Architektur. Die Implementierung kann je nach Anforderung an Ressourcenverbrauch oder Leistungsfähigkeit angepasst werden. Für die Anwendung im GPS Empfänger ist zum Beispiel der Hardware Multiplizierer und Barrel Shifter vorteilhaft. Die Anbindung von Peripherie kann über Memory Mapped I/O geschehen, oder über den Wishbone Bus (ein Bus Standard zur Anbindung verschiedener Cores innerhalb von integrierten Schaltkreisen). Für die Anbindung der \emph{TrackingHW} Instanzen wurde die Anbindung mit Memory Mapped I/O gewählt. Weitere Informationen zum MBlite Prozessor sind in \cite{MBliteThesis} nachzulesen.

\subsection{Frontend Parameter}
Die wichtigsten Parameter des Frontend sind die ZF Frequenz - und damit die PLL Parameter - die Einstellung des ZF Filters, und die Parameter des AD Wandlers. Die Dokumentation des MAX2769 Frontend ICs ist leider an vielen Stellen sehr lückenhaft. Daher mussten die optimalen Einstellungen teils durch Ausprobieren ermittelt werden.

\begin{table}[htbp]
    \ttabbox
    {
        \caption[Zusammenfassung Frontend Parameter]{Übersicht der wichtigsten Frontend Parameter}
        \label{TabFrontendParams}
    }
    {
        \rowcolors{2}{light-gray}{White}
    \begin{tabular}{c S l}
        \toprule
        Bezeichnung             &  {Wert} & Anmerkung\\
        \midrule
        $f_{ZF}$      & \SI{2.048}{\MHz}      & Zwischenfrequenz\\
        $f_{LO}$      & \SI{1573.374}{\MHz}   & Lokaloszillator\\
        NDIV        & \num{1538}            & PLL Hauptteiler\\
        RDIV        & \num{16}              & PLL Referenzteiler\\
        $f_S$       & \SI{16.368}{\MHz}     & Samplingrate \\
        $m$           & \num{1}               & Quantisierer Bits \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\FGimg[Vereinfachtes MAX2769 Blockschaltbild]{FrontendSimplified.png}{Vereinfachtes Blockschaltbild des MAX2769 GPS Frontends. Vor dem Mischer filtert ein externer Bandpass das GPS L1 Signal.}{0.9\textwidth}

\paragraph{ZF und PLL Parameter}
Bei der Erzeugung des LO Signals stehen im Frontend eine Integer PLL oder eine Fractional PLL zur Auswahl. Experimentell wurde bestimmt, dass die Integer PLL weniger Interferenzen verursacht, und die besten Ergebnisse bei einer ZF von etwa \SI{2}{\MHz} erreicht werden können. Bei der Auswahl der PLL Teilerfaktoren muss darauf geachtet werden, dass die geteilten Frequenzen in den im Datenblatt \cite{max2769} angegebenen Grenzen bleiben und $f_{comp}=f_{ref}/R$ muss zu dem Loop Filter der Frontend PLL passen. Das \comboard verwendet für den Loop Filter die Werte aus dem Datenblatt, wonach $f_{comp}=\SI{1.023}{\MHz}$ sein soll. Falls der komplexe Bandpass verwendet wird, muss außerdem die LO Frequenz unterhalb der Eingangsfrequenz liegen, da der komplexe Bandpass das untere Seitenband herausfiltert.
Mit dem \SI{16.368}{MHz} \gls{TCXO} auf dem \comboard ergibt sich damit $R=16$. $f_ZF$ soll im Bereich \SI{2}{\MHz} liegen, womit $N=1538$ zu wählen ist. Damit ergibt sich $f_{ZF}=f_{L1}-f_{TCXO}\cdot \frac{N}{R}=\SI{2.046}{MHz}$.

\paragraph{ZF Filter}
Als Konfiguration für das ZF Filter im Frontend wurde das komplexe Bandpassfilter gewählt. Das komplexe Bandpassfilter ist bei Anwendungen mit einer ZF $\neq 0$ zu bevorzugen, da damit die Spiegelfrequenzen unterdrückt werden\footnote{Falls die ZF zu \SI{0}{\Hz} gewählt wird sollte als ZF Filter das reelle Tiefpassfilter gewählt werden, um Satellitensignale mit negativer Doppleverschiebung nicht zu unterdrücken.}. Die untere Schranke für die Bandbreite ergibt sich aus dem Shannon-Nyquist Theorem zu $B\geq 2/\gpsTchip=\SI{1.023}{\MHz}$. Jegliche Filterung verschlechtert zwar das $E_b/N_0$, ist allerdings erforderlich um Aliasing bei der AD Wandlung zu verhindern. Wie in \cite{hegarty2011analytical} und \cite{itc1982chang} untersucht wurde, bringen allerdings Bandbreiten $B>2/\gpsTchip$ nur marginal geringere Verschlechterungen. \cite{hegarty2011analytical} nennt zum Beispiel eine Verbesserung von lediglich \SI{0.41}{\dB} wenn statt $B=2/\gpsTchip$ eine Bandbreite von $B=10/\gpsTchip$ gewählt wird. Deshalb wurde als Bandbreite $B=\SI{2.5}{\MHz}$ gewählt.

Die Mittenfrequenz $f_{cen}$ des ZF Filters lässt sich auf die gewählte ZF über ein \SI{6}{\bit} Konfigurationswort ($\textrm{FCEN}$) anpassen. Die Berechnung des Konfigurationsworts ist leider nicht im MAX2769 Datenblatt dokumentiert, es konnte aber herausgefunden werden, dass das korrekte Konfigurationswort mit folgender Gleichung ermittelt werden kann: 
\begin{equation}
    \textrm{FCEN'} = 64 - \frac{f_{cen}}{\Delta f}
\end{equation}
wobei $\textrm{FCEN'}$ das gespiegelte Konfigurationswort $\textrm{FCEN}$ ist (wenn z.B. $\textrm{FCEN'}=101100$, dann ist $\textrm{FCEN}=001101$) und $\Delta f=\SI{0.195}{\MHz}$  für $B=\SI{0.195}{\MHz}$.

\paragraph{Quantisierung und Samplingrate}
Zusätzlich zu der Bandpassfilterung wird auch durch Quantisierung und Abtastung das $E_b/N_0$  des Signals leicht verschlechtert. Der genaue Zusammenhang wurde ebenfalls in \cite{hegarty2011analytical} und \cite{itc1982chang} untersucht. Wie \cite{itc1982chang} schreibt hängt die Verschlechterung vor allem von der Anzahl der Bits $m$ des Quantisierers, schwach von dem Produkt $B\cdot T$ und nur sehr schwach vom $E_b/N_0$ des Eingangssignals ab. \TR{TabDegradQuant} stellt die Werte für verschiedene Anzahl von Bits für einen Empfänger ohne Bandpassfilterung und hoher Abtrastrate dar. Das trotzdem auch viele kommerzielle GPS Empfänger lediglich 1-bit Quantisierer verwenden liegt zum einen daran, dass die Verschlechterung nicht sehr gravierend ist und zum anderen daran, dass sich dadurch die Implementierung stark vereinfacht: Die Mischer können durch einfache XOR Glieder implementiert werden, es sind keine Look-Up Tables für den Lokaloszillator notwendig usw. 

Trotzdem wurden einige Untersuchungen angestellt, welchen Vorteil höhere Quantisierungen in der Praxis bringen. Dabei stellte sich jedoch heraus, dass der Störabstand im Vergleich zu 1-bit Sampling sinkt. Als Ursache wurde vermutet, dass die zusätzlichen Schaltvorgänge innerhalb des ICs für Interferenzen sorgen. Aus diesem Grund verwendet auch der in dieser Arbeit entwickelte Empfänger nur 1 bit und nur die reellen ($I$) Samples.


\begin{table}[htbp]
    \ttabbox
    {
        \caption[$E_b/N_0$ Verschlechterung durch Quantisierung]{Kleinste mögliche $E_b/N_0$ Verschlechterung durch Quantisierung für verschiedene Anzahl von Bits. Gültig für einen Empfänger ohne Bandpassfilterung und hohe Abtastraten (aus \cite{hegarty2011analytical}).}
        \label{TabDegradQuant}
    }
    {
        \rowcolors{2}{light-gray}{White}
    \begin{tabular}{c c}
        \toprule
        \# Bits             &  Verschlechterung (dB)\\
        \midrule
        \num{1}         & \num{1,961} \\
        \num{1.5}    & \num{0.916} \\
        \num{2}           & \num{0.549} \\
        \num{2.5}    & \num{0.372} \\
        \num{3}           & \num{0.166} \\
        \bottomrule
    \end{tabular}
    }
\end{table}

Die Samplingrate kann über Teiler und Vervielfacher die Werte $\gpsftcxo$, $\gpsftcxo/2$, $\gpsftcxo/4$, oder $2\times \gpsftcxo$ annehmen\footnote{Es gibt außerdem noch ein Fractional Clock Divider, über den noch andere Teilraten eingestellt werden können.}. Bei der Auswahl muss ein Kompromiss gemacht werden zwischen Genauigkeit der Pseudorange Schätzung (\ref{positionsbestimmung}) und dem Speicherverbrauch für den Rohdatenpuffer. Unter Berücksichtigung der oben festgelegten Größe des Rohdatenpuffers \SI{10}{\ms} wird die Samplingrate auf  $f_S=\gpsftcxo=\SI{16.368}{\MHz}$ festgelegt. Damit werden mit dem 1-bit Quantisierer mindestens \SI{163.69}{\kilo\bit} Speicher benötigt\footnote{Weil der Puffer als FIFO implementiert wird sind Speichergrößen von Zweierpotenzen vorteilhaft. Daher umfasst der Puffer \SI{262144}{\bit}, und damit etwa \SI{16}{\ms}}.

\paragraph{Andere Einstellungen} Neben den oben genannten Parametern bietet das MAX2769 Frontend noch viele weitere Einstellungen. Die meisten wurden dabei auf den Voreinstellungen belassen. Abweichend davon wurde beim Flugmodell die Phantomspeisung abgeschaltet und LNA1 ausgewählt, da dieser für passive Antennen ausgelegt ist wie sie im \dscubesat verwendet werden\footnote{Bei dem COM1 Board wurde währende der Entwicklung eine aktive Antenne und der dafür optimierte LNA2 verwendet.}. Die \gls{AGC} ist zwar aktiviert, dürfte aber bei 1-Bit Sampling keinen Einfluss haben. Der \emph{GAINREF} Parameter wurde auf 255 gesetzt. Weiterhin wurde durch ausprobieren herausgefunden, dass sich die Erfolgsrate der Acquisition leicht verbessert wenn der Hochpassfilter vor dem \gls{PGA} abgeschaltet wird (\emph{FHIPEN}$=0$).


\section{Planung}
Nachdem im vorherigen Abschnitt die Rahmenbedingungen  entworfenen  wurden können nun die Arbeitspakete für die Implementierung etwas genauer festgelegt werden. 

Als erster Meilenstein wurde festgelegt Rohdaten vom MAX2769 Frontend sammeln zu können. Dazu muss die Schnittstelle zwischen FPGA und DSP implementiert werden, wofür auf FPGA Seite ein Gegenstück zu der EBIU Schnittstelle (\ref{ebiuinterface}) des DSP implementiert werden muss. Auf DSP Seite muss ein Kerneltreiber geschrieben werden um die Schnittstelle für Programme im User-Space zu abstrahieren. Da über die EBIU Schnittstelle lediglich \enquote{speicherartige} Peripherie angesprochen werden kann muss im FPGA Logik implementiert werden, die die AD Wandler Schnittstelle zu einem Speicher ähnlichen abstrahiert.

Als zweiter Meilenstein soll mit den nun verfügbaren Rohdaten in Matlab Acquisition und Tracking simuliert werden. Das Buch \cite{borre2007software} stellt mit dem SoftGNSS Empfänger eine Simulationsumgebung Bereit. Mit der Simulation und der funktionierenden Schnittstelle zu den Rohdaten können dann die Frontend Parameter optimiert werden.

Die Simulation im SoftGNSS Matlab Code ist nicht auf Echtzeitverarbeitung ausgelegt und unterscheidet sich deshalb stark von der endgültigen Implementierung im FPGA. Deshalb ist der dritte Meilenstein die Simulation des Tracking an eine Implementierung FPGA anzupassen. Dazu wird ein Simulink Modell erstellt welches sukzessive von einer High-Level Simulation  an die FPGA Implementierung angepasst wird.

Der nächste Meilenstein ist die Implementierung des Tracking im FPGA. Ausgehend von den Erkenntnissen der Low-Level Simulation in Simulink sollen die einzelnen Module in VHDL geschrieben und getestet werden. Insbesondere das Testen ist hier wichtig, da Debugging im FPGA zeitaufwändig ist.
Teil des Trackingloop ist wie schon erwähnt auch ein Softcore Prozessor. Hier wird auf einen vorgefertigten Softcore zurückgegriffen, dieser muss jedoch noch in das System integriert werden. Parallel dazu muss der Software Teil des Trackingloop geschrieben werden. Dazu müssen einige Mathematikfunktionen für Festkommaarithmetik implementiert werden.

Als nächster Meilenstein ist die Acquisition im DSP zu integrieren. Dazu muss zum Einen der Acquisition Algorithmus programmiert werden. Zum anderen muss die Kommunikation mit dem FPGA Teil implementiert werden, um Rohdaten anfordern zu können und die Ergebnisse an die Tracking Kanäle weitergegeben werden. Zusätzlich muss die Steuerung implementiert werden, die zum Beispiel überwacht ob ein Kanal die Verbindung verliert, beispielsweise weil ein Satellit außer Sicht geht.

Als fünfter Meilenstein ist die Extraktion der NAV Daten zu implementieren. Auch hier muss wieder die Kommunikation mit dem FPGA implementiert werden um die demodulierten Signale einzulesen. Da mit Verbindungsabbrüchen oder Übertragungsfehlern zu rechnen ist, muss diese Komponente auch solche Ausnahmen behandeln. 

Als finaler Meilenstein muss dann die Positionsbestimmung implementiert werden. Hier muss ebenfalls wieder die Kommunikation mit dem FPGA implementiert werden um die Codephase abzufragen. Mit den NAV Daten muss dann die Pseudorange berechnet werden. Weiterhin müssen aus den NAV Daten die Position der aussendenden Satelliten berechnet werden. Zu der Positionsbestimmung kann auch das Mitteln der Position gehören, oder die Berechnung eines Orbits des \dscubesat. Die Anforderungen hier sind noch nicht festgelegt.

Im folgenden ist noch eine Übersicht über die Schritte abgebildet. Die Meilensteine 1 bis 3 sind zu diesem Zeitpunkt bisher implementiert worden.

\begin{enumerate}
\item Schnittstelle zum Übertragen der Rohdaten zum DSP
    \begin{enumerate}
    \item Linux Kerneltreiber
    \item EBIU Schnittstelle im FPGA
    \item GPS Frontend Abstraktion (z.B. FIFO) im FPGA
    \end{enumerate}
\item Simulation in Matlab
    \begin{enumerate}
    \item Acquisition \& Tracking mit SoftGNSS Receiver
    \item Tracking Simulation in Simulink
    \item Sukzessive an die Implementierung im FPGA anpassen
    \end{enumerate}
\item Implementierung des Tracking im FPGA
    \begin{enumerate}
    \item \emph{TrackingHW} Komponente in VHDL
    \item Integrieren des Softcore Prozessors
    \item Schreiben der Software (\emph{TrackingSW} Komponente)
    \end{enumerate}
\item Implementierung der Acquisition im DSP
\begin{enumerate}
    \item Anfordern von Rohdaten
    \item Senden der Ergebnisse an Tracking Kanäle
    \item Steuerung und Überwachung des Kanal Status
\end{enumerate}
\item Extraktion der NAV Daten
\begin{enumerate}
    \item Frame Synchronisation
    \item Paritätskontrolle
    \item Ausnahmebehandlung bei Fehlerhaften Daten
\end{enumerate}
\item Berechnung der Position
    \begin{enumerate}
    \item Positionsberechnung der GPS Satelliten
    \item Pseudorange Berechnung
    \item Koordinatentransformation
    \end{enumerate}
\end{enumerate}

% Meilensteine:
% Daten von Frontend nehmen, puffern und an DSP Übertragen
%% Kerneltreiber schreiben
%%% SPI, DMA
%% FIFO im FPGA implementieren
%%% EBIU Schnittstelle/State Machine
% Damit Acquisition in Matlab durchführen
% Trackingloop in Matlab simulieren
%% High Level (LUT, sin, cos)
%% Dann Low Level (LFSR, NCO)
% Implementierung Tracking FPGA
% Softwareschnittstelle FPGA<-> DSP
% Implementierung Acquisiton DSP

\subsection{Schnittstelle zum Übertragen der Rohdaten}
In diesem Abschnitt wird die Schnittstelle auf der Software Ebene aus Sicht des DSP beschrieben. Es wird schon einmal eine grobe Erklärung des Ablaufs auf Anwendungs-, Kernel- und Hardware Ebene gegeben. Weitere Details werden später noch im Kapitel \ref{Kerneltreiber} gegeben. Eine Anmerkung vorab: Die Beschreibung stellt den Stand zum Zeitpunkt der Entwicklungsphase dar und wurde für die Rohdatenübertragung auch so implementiert und funktioniert. Für die weitere Entwicklung ist jedoch ein Wechsel auf das \emph{Linux User I/O} Framework angedacht, da dies zukünftige Entwicklungsschritte vereinfachen wird. 
%Einige Erklärungen dazu folgen im zweiten Unterabschnitt.

\subsubsection{Linux File I/O Schnittstelle}
Unter Linux werden Hardware/Software Schnittstellen typischerweise über \emph{device files} (auch \emph{special files} genannt) realisiert. Dabei abstrahiert ein Treiber die darunterliegende Hardware so, dass die Anwendung Daten durch einfach Lese-/ Schreib Operationen lesen und schreiben kann, genau wie bei einer \enquote{normalen} Datei. Es gibt einige verschiedene Typen von device files, von denen die wichtigsten \emph{Character Devices} und \emph{Block Devices} sind. 

\emph{Block Devices} liefern die Daten, wie der Name schon sagt, blockweise\footnote{Die Blockgröße kann dabei natürlich auch einfach nur ein Zeichen sein. Damit ist der wahlfreie Zugriff das Hauptunterscheidungsmerkmal.} aus und verfügen über wahlfreien Zugriff. Typische Beispiele sind Festplatten.

\emph{Character Devices} liefern die Daten Zeichenweise aus, eine Positionierung innerhalb des Datenstroms ist dabei nicht möglich. Typische Beispiele sind Maus und Tastatur. Hier ist offensichtlich, dass wahlfreier Zugriff nicht möglich ist. Die Rohdatenschnittstelle verhält sich ähnlich, es können immer nur so viele Daten gelesen werden, wie zur Verfügung stehen, ein Wahlfreier Zugriff darüber hinaus ist nicht möglich. Deshalb soll die Schnittstelle als Character Device implementiert werden. Der Treiber erzeugt dann ein Character Device File, z.B. \lstinline$/dev/gps$. Damit können die Rohdaten auf Anwendungsseite mit einfachen Funktionen der C Standardbibliothek (\lstinline$fid=fopen("/dev/gps", "r")$ und \lstinline$fread(fid, ...)$ usw.) gelesen werden (\FR{GPS_UML_seq_FileIO.pdf}).

\FGimg[Linux File I/O Sequenzdiagramm]{GPS_UML_seq_FileIO.pdf}{Ablauf eines Lesezugriffs auf das Character Device File}{0.9\textwidth}

\subsubsection{Treiberebene}
Der Aufruf einer der oben genannten Funktionen (\lstinline$fopen$ und \lstinline$fread$ usw.) ruft einen System Call auf, beispielsweise  \lstinline$open$ oder \lstinline$read$. 

Der Treiber muss für ein Characterdevice einige Funktionen implementieren, die in der Linux Header Datei \lstinline$fs.h$ mit der Struktur \lstinline$fops$ angegeben sind. Die Struktur \lstinline$fops$ enthält Zeiger auf die Gegenstücke zu den System Calls, z.B. \lstinline$fops.read = gps_read$.

Nachdem der Linux Kernel festgestellt hat, welches Kernelmodul für die Datei zuständig ist, leitet er die System Calls an die Gegenstücke im Treiber weiter. Innerhalb des Gegenstück, bsp. \lstinline$gps_read$ passiert dann alles was notwendig ist um die angeforderten Daten zu liefern. Für den Fall \lstinline$gps_read$ bedeutet das: Die EBIU Schnittstelle muss für den Asynchronen Zugriff konfiguriert werden. Dann muss überprüft werden wie viele Daten zum Lesen verfügbar sind. Dann muss der DMA Controller initialisiert werden mit der Quell- und Zieladresse und der Anzahl zu lesenden Bytes. Zum Schluss muss die DMA Übertragung freigegeben werden und nach Beendigung der Kernel über die Anzahl gelesenen Bytes informiert werden.

\subsubsection{Hardware Ebene}
Auf der FPGA Seite müssen die Daten gepuffert werden, da der DSP nicht immer sofort bereit ist die Daten zu empfangen. Dazu gibt es verschiedene Möglichkeiten: Die Daten können beispielsweise einfach in einen Speicher geschrieben werden, der durch einen im FPGA implementierten Adressdekoder  auf einen Speicherbereich des DSP abgebildet wird (\FR{FIFO_vs_plain_memory.png} Variante B). Der entscheidende Nachteil hierbei ist jedoch, dass die Schreib- und Lesezeiger über die Schnittstellengrenze hinweg synchronisiert werden müssen, weil sonst keine Erkennung möglich ist ob der Puffer voll oder leer ist. Insbesondere, weil eine Synchronisation über Taktgrenzen hinweg immer problematisch ist, ist diese Variante sehr ungünstig.

Eine bessere Variante ist die Daten in eine \gls{FIFO} Warteschlange zu schreiben (\FR{FIFO_vs_plain_memory.png} Variante A). Hierbei bildet der Adressdekoder lediglich den FIFO Ausgang auf eine einzige Speicherzelle ab. Zum Lesen von mehreren Datenwörtern wird immer wieder von der selben Speicherzelle gelesen und der FIFO im FPGA sorgt automatisch dafür, dass das nächste Wort bereit steht.

\FR{GPS_UML_Rohdatenpuffer.pdf} zeigt noch ein bisschen mehr den internen Aufbau auf FPGA Seite. Der \emph{Slave EBIU Controller} ist hier das Gegenstück im FPGA zu dem EBIU Controller im DSP ( \FR{EBIU_blockdiagram.pdf}). Er sorgt dafür die externe Asynchrone Schnittstelle auf den internen synchronen Daten- und Adressbus umzusetzen. Der Adressdekoder wertet den Adressbus aus und selektiert die entsprechenden Komponente, die ihre Daten auf den Bus legen soll.


\FGimg[Vergleich FIFO und RAM Block Puffer]{FIFO_vs_plain_memory.png}{Vergleich des FIFO Datenpuffers (\emph{A}) mit dem Speicherblock Puffer (\emph{B}). Der entscheidende Nachteil von \emph{B} ist, dass die Schreib- und Lesezeiger über die Schnittstellengrenze hinweg synchronisiert werden müssen.}{0.95\textwidth}

\FGimg[Rohdatenschnittstelle auf Hardware Ebene]{GPS_UML_Rohdatenpuffer.pdf}{Rohdatenschnittstelle auf Hardware Ebene. Die Rohdaten werden in einen FIFO geschrieben. Der DSP kann auf den FIFO über das EBIU Interface wie auf einen Speicher zugreifen.}{0.6\textwidth}

\subsubsection{User I/O Schnittstelle}
Am Anfang des Abschnitts wurde bereits erwähnt, dass die im obigen Abschnitt beschriebene File I/O Schnittstelle nur den bisherigen Entwicklungsstand widerspiegelt. Für das reine Übertragen der Rohdaten funktioniert diese auch sehr gut, da dies ein Stream-orientiertes Interface ist. Aber wenn man sich noch einmal \FR{GPS_UML_deployment1.png} ansieht, müssen für die Meilensteine 4-5 noch zahlreiche weitere Daten übertragen werden, wie z. B. die Loop Parameter nach Beendigung der Acquisition.

Freilich lässt sich dies auch allen in ein Kernelmodul verpacken. Jedoch birgt steigende Komplexität immer die Gefahr von Fehlern. Fehler die auf Kernelebene passieren, können möglicherweise zum Systemabsturz führen. Mit dem \emph{User I/O} Framework bietet der Kernel auch Mittel an User-Space Programmen direkten Zugriff auf Hardware zu geben. Das Kernel Modul sorgt hilft lediglich bei der Einrichtung, verfügt aber selbst über relativ wenig Intelligenz. 

Eine Detaillierte Beschreibung würde an dieser Stelle zu weit gehen, insbesondere, da der Entwurf für diese Erweiterung nicht durchgeführt wurde. Das User I/O Framework ist in \cite{uioHowto} dokumentiert. Der kurze Abschnitt soll mehr als Hinweis für zukünftige Arbeiten dienen.

% Je mehr intelligenz in das Kernel modul gepackt werden muss, desto größer ist die gefahr das etwas schief läuft -> Systemabsturz

\subsection{Entwurf der Parameter für die Acquisition}
Die wichtigen Parameter für die Acquisiton sind die Grenzen des zu durchsuchenden Raums (\#Codes $\times$ \#Codephasen $\times$ \#Frequenzklassen) und der Schwellwert ab der ein Signal als \emph{erkannt} gewertet werden soll.

Die Menge der zu durchsuchenden Codes ist durch die Anzahl der aktiven GPS Satelliten gegeben, denen die PRN 1 bis 32 zugewiesen sind. 

Der Menge der möglichen Codephasen ergibt sich aus der Codedauer $\gpsTcode$ und der Frontend Sampling Frequenz\footnote{Die Samplingfrequenz im Flugmodell beträgt \SI{16.368}{\mega\hertz}. Das während der Entwicklung benutzte COM Board nutzt eine Samplingfrequenz von  \SI{16.369}{\mega\hertz}} des Frontend ICs:  
\begin{equation}
    N=fs\cdot \gpsTcode=\SI{16.368}{\mega\hertz}\cdot \SI{1}{\milli\second} = 16369
\end{equation} 

Da der Doppler Shift die Hauptursache ist entspricht die Abweichung der maximal erwarteten Dopplerverschiebung. Wie in Kapitel \ref{Dopplereffekt} besprochen, ist der erwartete Doppler Shift \SI{\pm45}{\kilo\hertz}. In der SoftGNSS Simulation wird eine Klassengröße von \SI{500}{\Hz} verwendet, die in Versuchen gute Ergebnisse gezeigt hat. Damit ergeben sich 180 Frequenzklassen.

Die Schwelle, ab der ein Signal nach dem ersten Schritt der Acquisition als \enquote{vorhanden} bewertet wird, wird auf ein \emph{Peak-to-Second-Peak Ratio} von \num{2.5} festgelegt. Dieser Wert wurde aus dem SoftGNSS Simulator übernommen und ist der Wert, den Signale erreichen, die ein gerade noch für das Tracking ausreichendes SNR haben.

\subsection{Tracking Loop Filter}
Die entscheidenden Entwurfsparameter für den Carrier- und Code Tracking Loop sind die Parameter Dämpfungsgrad $\zeta$ und Bandbreite $B_L$ des geschlossenen Regelkreises. Zusammen bestimmen diese die Schnelligkeit mit der der Regelkreis einrastet und die Rauschbandbreite des Steuersignals für den LO. 

Die Werte für den Loopfilter wurden zunächst aus \cite{borre2007software} bzw. dem SoftGNSS Simulator übernommen und anschließend, im Hinblick auf den höheren Dynamikbereich der Dopplerverschiebung auf dem Dragsail Cubesat überprüft. Die Extremwerte der Änderungsrate der Dopplerverschiebung wurden bereits in Abschnitt \ref{Dopplereffekt} bestimmt. In der Simulation ergab sich, dass der Trackingloop auch bei der maximalen erwarteten Änderung der Dopplerverschiebung von \SI{61}{\Hz\per\second} zuverlässig regelt. 

\TR{TabLoopFilter} stellt die verwendeten Loop Parameter dar.
Die Beziehung zwischen $\zeta$ und $B_L$ und den eigentlichen Koeffizienten des digitalen Filters wurde bereits in Abschnitt \ref{loopfilter} beschrieben.


\begin{table}[htbp]
    \ttabbox
    {
        \caption[Tracking Loop Parameter]{Trackingloop Parameter}
        \label{TabLoopFilter}
    }
    {
        \rowcolors{2}{light-gray}{White}
    \begin{tabular}{c c l}
        \toprule
        Name             & Wert & Beschreibung \\
        \midrule
        $B_{carrier}$ & \SI{25}{\Hz} &  Rauschbandbreite Carrier Loop Filter\\
        $\zeta_{carrier}$ & \num{0.7}& Dämpfung Carrier Loop Filter \\
        $B_{carrier}$ & \SI{5}{\Hz} &  Rauschbandbreite Code Loop Filter\\
        $\zeta_{carrier}$ & \SI{0.7}& Dämpfung Code Loop Filter \\
        \bottomrule
    \end{tabular}
}
\end{table}

\subsubsection{Festkommaentwurf der Loop Filter}
Im Hinblick auf die Echtzeitfähigkeit und Stabilität des Regelkreises muss auf die Performanz und die begrenzte Rechengenauigkeit, der Berechnungen geachtet werden. Während in der Matlab Simulation, die nicht Echtzeitfähig ist, mit Fließkommawerten doppelter Genauigkeit gerechnet wird, soll in der Implementierung mit Festkommawerten gerechnet werden. Festkommaalgorithmen sind zwar in der Entwurfsphase deutlich aufwändiger, aber bringen in der Implementierung erhebliche Performanzvorteile.

Für den Festkommaentwurf muss das Zahlenformat sorgfältig ausgewählt werden, damit der durch die Festkommazahl darstellbare Dynamikbereich optimal ausgenutzt wird. Im Folgenden wird der Festkommaentwurf für die Filter besprochen\footnote{Eine Einführung zu Festkommazahlen, der hier verwendeten Notation und Berechnungen damit wird in Appendix \ref{AppendixFestkomma} gegeben.}.

\paragraph{Rahmenbedingungen} Der verwendete Softcore ist ein \SI{32}{\bit} Prozessor, weshalb nur Zahlenformate mit maximal  \SI{32}{\bit} in Betracht kommen\footnote{Auf Hochsprachenebene lassen sich natürlich auch \SI{>32}{\bit} Worte verarbeiten. Dies geht aber auf Kosten der Performanz.}. Weiterhin verfügt der Prozessor über \SI{32}{\bit} Multiplizierer. Da das Produkt wieder in \SI{32}{\bit} passen muss, sollen Multiplikand und Multiplikator maximal \SI{16}{\bit} umfassen.

\paragraph{Berechnung der Filterkoeffizienten}
Mit den Formeln \eqref{Eq:FilterB0} bis \eqref{Eq:FilterA1} lassen sich die Koeffizienten der digitalen Filter zahlenwertmäßig berechnen. Die Parameter $B_L$ und $\zeta$ sind bereits oben in \TR{TabLoopFilter} aufgeführt. Zur Berechnung fehlen noch die Parameter $K_0$ (das VCO Gain) und $K_d$ (das Phasendiskriminator Gain). 


\subparagraph{Carrier Loop}
Wie man sehr gut in \FR{arctandiscriminator.png} sehen kann ist für den Carrier Loop Diskriminator $K_{d,carr}=1$. Das VCO Gain ist
\begin{equation}
    K_{0,carr} = \frac{2 pi \gpsfsamp}{2^N}
\end{equation}
wobei N für den Carrier Loop $N_{carr}=28$ ist. Warum sich das Gain genau so ergibt soll hier zunächst noch nicht erklärt werden, dies wird später im Abschnitt \ref{VCOimplementierung} klar.

\subparagraph{Code Loop}
Der Phasendiskriminator der beim Codeloop zum Einsatz kommt  $K_{d,carr}=1$. Das VCO Gain ist
\begin{equation}
    K_{0,carr} = \frac{2 pi \gpsfsamp}{2^N}
\end{equation}
wobei N für den Carrier Loop $N_{carr}=28$ ist. Warum sich das Gain genau so ergibt soll hier zunächst noch nicht erklärt werden, dies wird später im Abschnitt \ref{VCOimplementierung} klar.

\begin{table}[htbp]
    \ttabbox
    {
        \caption[Filter Koeffizienten]{Trackingloop Parameter}
        \label{TabFilterKoeff}
    }
    {
        \rowcolors{2}{light-gray}{White}
    \begin{tabular}{c c c}
        \toprule
                & Carrier Loop      & Code Loop     \\
        \midrule
        $b_0$   &  \num{67.3347}    & \num{13.2880} \\
        $b_1$   &  \num{-65.0977}   &  \num{-13.1985}\\
        $a_0$   &  \num{1}          &  \num{1}      \\
        $a_1$   &  \num{-1}         &  \num{-1}     \\
        \bottomrule
    \end{tabular}
}
\end{table}
%\subsubsection{NAV Daten Auswertung}
%Präambel usw


% Komponenten: Acquisition, Tracking...
\subsection{Softwareschnittstelle FPGA/DSP}




%Character Device Treiber
%Je Kanal ein FIFO
% Auf Software Seite werden die Kanäle durch Klassen repräsentiert. Abstraktion der Hardware Kanäle

\subsection{Matlab Simulation}
%Trackingloop in Simulink

%High Level Simulation sukzessive angepasst an Implementierung in Hardware
%Acquisition Skripte
% MAX2769 Bandpassfilter mittenfrequenz
% 1bit vs >1bit: Große Störungen bemerkt bei >1bit